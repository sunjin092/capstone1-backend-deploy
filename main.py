# âœ… main.py (CV ë¶„ì„ + ì¶”ì²œ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©)

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image, ImageOps
import pandas as pd
import json
import io
import numpy as np
import math
import os
import torch
import torch.nn as nn
from torchvision import transforms, models
import cv2
import mediapipe as mp
from typing import List, Optional
from sklearn.preprocessing import StandardScaler
from typing import List

# FastAPI ì•± ìƒì„±
app = FastAPI()

# CORS ì„¤ì •
origins = [
    "http://localhost:3000",
    "https://jiwow-wow.github.io",
    "https://front-seven-chi.vercel.app"
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê³µí†µ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

regression_ckpt = os.path.join("checkpoint", "regression")
regression_num_output = [1, 2, 0, 0, 0, 3, 3, 0, 2]
area_label = {0: "ì „ì²´", 1: "ì´ë§ˆ", 2: "ë¯¸ê°„", 3: "ì™¼ìª½ ëˆˆê°€", 4: "ì˜¤ë¥¸ìª½ ëˆˆê°€", 5: "ì™¼ìª½ ë³¼", 6: "ì˜¤ë¥¸ìª½ ë³¼", 7: "ì…ìˆ ", 8: "í„±"}
reg_desc = {0: ["ìƒ‰ì†Œì¹¨ì°©"], 1: ["ìˆ˜ë¶„", "íƒ„ë ¥"], 5: ["ìˆ˜ë¶„", "íƒ„ë ¥", "ëª¨ê³µ"], 6: ["ìˆ˜ë¶„", "íƒ„ë ¥", "ëª¨ê³µ"], 8: ["ìˆ˜ë¶„", "íƒ„ë ¥"]}

REGION_LANDMARKS = {
    0: list(range(468)),
    1: [10, 67, 69, 71, 109, 151, 337, 338, 297],
    2: [168, 6, 197, 195, 5, 4],
    3: [130, 133, 160, 159, 158],
    4: [359, 362, 386, 385, 384],
    5: [205, 50, 187, 201, 213],
    6: [425, 280, 411, 427, 434],
    7: [13, 14, 17, 84, 181],
    8: [152, 377, 400, 378, 379]
}

def crop_regions_by_ratio(pil_img):
    img = np.array(pil_img)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    h, w = img.shape[:2]
    regions = [None] * 9
    with mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:
        results = face_mesh.process(img_rgb)
        if not results.multi_face_landmarks:
            raise ValueError("â— ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        landmarks = results.multi_face_landmarks[0].landmark
        points = np.array([(lm.x * w, lm.y * h) for lm in landmarks])
        face_x1, face_y1 = np.min(points, axis=0)
        face_x2, face_y2 = np.max(points, axis=0)
        face_w, face_h = face_x2 - face_x1, face_y2 - face_y1
        for idx, lm_indices in REGION_LANDMARKS.items():
            pts = np.array([(landmarks[i].x * w, landmarks[i].y * h) for i in lm_indices])
            cx, cy = np.mean(pts, axis=0)
            if idx == 8: cx -= face_w * 0.15
            if idx == 1:
                box_w, box_h = int(face_w * 0.70), int(face_h * 0.3)
                cy -= box_h * 0.2
            elif idx == 2:
                box_w, box_h = int(face_w * 0.35), int(face_h * 0.15)
                cy -= box_h * 2.5
            else:
                box_w, box_h = int(face_w * 0.28), int(face_h * 0.25)
            x1, y1 = max(int(cx - box_w / 2), 0), max(int(cy - box_h / 2), 0)
            x2, y2 = min(int(cx + box_w / 2), w), min(int(cy + box_h / 2), h)
            crop = img[y1:y2, x1:x2]
            regions[idx] = Image.fromarray(crop)
    return regions

def load_average_data(path):
    df = pd.read_csv(path, encoding='cp949')
    avg_dict = {}
    for _, row in df.iterrows():
        key = row["ì„±ë³„"]
        avg_dict[key] = {
            "mean": {
                "ìˆ˜ë¶„_ì´ë§ˆ": row["ìˆ˜ë¶„_ì´ë§ˆ"],
                "ìˆ˜ë¶„_ì™¼ìª½ ë³¼": row["ìˆ˜ë¶„_ì™¼ìª½ ë³¼"],
                "ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼": row["ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼"],
                "ìˆ˜ë¶„_í„±": row["ìˆ˜ë¶„_í„±"],
                "íƒ„ë ¥_ì´ë§ˆ": row["íƒ„ë ¥_ì´ë§ˆ"],
                "íƒ„ë ¥_ì™¼ìª½ ë³¼": row["íƒ„ë ¥_ì™¼ìª½ ë³¼"],
                "íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼": row["íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼"],
                "íƒ„ë ¥_í„±": row["íƒ„ë ¥_í„±"],
                "ëª¨ê³µ_ì™¼ìª½ ë³¼": row["ëª¨ê³µ_ì™¼ìª½ ë³¼"],
                "ëª¨ê³µ_ì˜¤ë¥¸ìª½ ë³¼": row["ëª¨ê³µ_ì˜¤ë¥¸ìª½ ë³¼"],
                "ìƒ‰ì†Œì¹¨ì°©_ì „ì²´": row["ìƒ‰ì†Œì¹¨ì°©_ì „ì²´"]
            },
            "std": {
                "ìˆ˜ë¶„_ì´ë§ˆ": row["ìˆ˜ë¶„_ì´ë§ˆ_í‘œì¤€í¸ì°¨"],
                "ìˆ˜ë¶„_ì™¼ìª½ ë³¼": row["ìˆ˜ë¶„_ì™¼ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼": row["ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ìˆ˜ë¶„_í„±": row["ìˆ˜ë¶„_í„±_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_ì´ë§ˆ": row["íƒ„ë ¥_ì´ë§ˆ_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_ì™¼ìª½ ë³¼": row["íƒ„ë ¥_ì™¼ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼": row["íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_í„±": row["íƒ„ë ¥_í„±_í‘œì¤€í¸ì°¨"],
                "ëª¨ê³µ_ì™¼ìª½ ë³¼": row["ëª¨ê³µ_ì™¼ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ëª¨ê³µ_ì˜¤ë¥¸ìª½ ë³¼": row["ëª¨ê³µ_ì˜¤ë¥¸ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ìƒ‰ì†Œì¹¨ì°©_ì „ì²´": row["ìƒ‰ì†Œì¹¨ì°©_ì „ì²´_í‘œì¤€í¸ì°¨"]
            }
        }
    return avg_dict

def compute_z_score(value, mean, std):
    if std == 0:
        return 0
    return round((value - mean) / std, 2)

def safe_float(val, default=0.0):
    try:
        if val is None or math.isnan(val) or math.isinf(val):
            return default
        return float(val)
    except:
        return default

def get_restore_stats():
    return {
        1: {"ìˆ˜ë¶„": (60.6, 10.1), "íƒ„ë ¥": (48.7, 11.9)},
        5: {"ìˆ˜ë¶„": (60.6, 10.1), "íƒ„ë ¥": (48.7, 11.9), "ëª¨ê³µ": "log"},
        6: {"ìˆ˜ë¶„": (60.2, 9.6),  "íƒ„ë ¥": (49.3, 12.1), "ëª¨ê³µ": "log"},
        8: {"ìˆ˜ë¶„": (61.3, 10.0), "íƒ„ë ¥": (47.5, 12.0)},
        0: {"ìƒ‰ì†Œì¹¨ì°©": 300}
    }

# íšŒê·€ ëª¨ë¸ ë¡œë”©
restore_stats = get_restore_stats()
reg_models = []
for idx, out_dim in enumerate(regression_num_output):
    if out_dim == 0:
        reg_models.append(None)
        continue
    model = models.resnet50(weights=None)
    model.fc = nn.Linear(model.fc.in_features, out_dim)
    ckpt_path = os.path.join(regression_ckpt, str(idx), "state_dict.bin")
    if os.path.exists(ckpt_path):
        state = torch.load(ckpt_path, map_location=device)
        if "model_state" in state:
            state = state["model_state"]
        model.load_state_dict(state, strict=False)
        model.eval()
        reg_models.append(model.to(device))
    else:
        reg_models.append(None)

def model_image(image: Image.Image, gender_age: str, average_data_path="average_data.csv") -> dict:
    image = ImageOps.exif_transpose(image.convert("RGB"))
    regions = crop_regions_by_ratio(image)

    result = {"regions": {}, "z_scores": {}, "z_score_avg": {}, "priority_concern": None}

    avg_data = load_average_data(average_data_path)
    if gender_age not in avg_data:
        raise ValueError(f"â— í‰ê·  ë°ì´í„°ì— '{gender_age}' í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    mean_dict = avg_data[gender_age]["mean"]
    std_dict = avg_data[gender_age]["std"]

    z_score_list = []
    label_z_dict = {}

    for idx in range(9):
        if reg_models[idx] is None or regions[idx] is None or idx in [3, 4]:
            continue
        crop_tensor = transform(regions[idx]).unsqueeze(0).to(device)
        with torch.no_grad():
            output = reg_models[idx](crop_tensor).squeeze().cpu().numpy()
        if output.ndim == 0:
            output = [output]
        sub_result, sub_zscore = {}, {}
        for i, val in enumerate(output):
            label = reg_desc[idx][i]
            if label == "ëª¨ê³µ" and restore_stats[idx].get(label) == "log":
                val = np.clip(np.exp(val) - 1, 0, 2500)
            elif isinstance(restore_stats[idx].get(label), tuple):
                mean, std = restore_stats[idx][label]
                val = val * std + mean
            elif label == "ìƒ‰ì†Œì¹¨ì°©":
                val *= 300
            val = float(val)
            sub_result[label] = round(val, 2)
            z_key = f"{label}_{area_label[idx]}" 
            if z_key in mean_dict:
                z = compute_z_score(val, mean_dict[z_key], std_dict[z_key])
                sub_zscore[label] = z
                z_score_list.append((label, area_label[idx], z))
                label_z_dict.setdefault(label, []).append(z)
        result["regions"][area_label[idx]] = sub_result
        if sub_zscore:
            result["z_scores"][area_label[idx]] = sub_zscore

    result["z_score_avg"] = {label: round(np.mean(zlist), 2) for label, zlist in label_z_dict.items()}

    concerns = []
    for label, area, z in z_score_list:
        if label in ["ìˆ˜ë¶„", "íƒ„ë ¥"] and z < -0.2:
            concerns.append((label, area, z))
        elif label in ["ëª¨ê³µ", "ìƒ‰ì†Œì¹¨ì°©"] and z > 0.2:
            concerns.append((label, area, z))
    if concerns:
        result["priority_concern"] = sorted(concerns, key=lambda x: abs(x[2]), reverse=True)[0]

 
    return result

# í™”ì¥í’ˆ CSV ë¡œë“œ
products = pd.read_csv("Total_DB.csv", encoding='cp949')

def recommend_products(regions: dict, priority_concern: Optional[tuple], user_selected_concerns: Optional[List[str]] = None):

    # âœ… priority_concernì€ ë‹¨ì¼ íŠœí”Œì´ë¯€ë¡œ, ì•ˆì „í•˜ê²Œ ì²« ë²ˆì§¸ ìš”ì†Œë§Œ ì¶”ì¶œ
    if priority_concern:
        priority_label = priority_concern[0]
        user_concerns = [priority_label]
    else:
        user_concerns = []

    if user_selected_concerns is None:
        user_selected_concerns = []

    concern_keywords = {
        'ëª¨ê³µ ê°œìˆ˜': ['ëª¨ê³µê´€ë¦¬', 'ëª¨ê³µì¼€ì–´', 'í”¼ì§€ì¡°ì ˆ', 'ë…¸íë¬¼ì œê±°', 'ì•ˆí‹°í´ë£¨ì…˜','BHA', 'LHA'],
        'íƒ„ë ¥': ['í”¼ë¶€íƒ„ë ¥', 'ì£¼ë¦„ê°œì„ ', 'í”¼ë¶€ì¥ë²½ê°•í™”', 'í”¼ë¶€ì¬ìƒ', 'ì˜ì–‘ê³µê¸‰', 'ì•°í”Œ', 'í”¼ë¶€í™œë ¥', 'ìƒê¸°ë¶€ì—¬'],
        'ìˆ˜ë¶„': ['ìˆ˜ë¶„ê³µê¸‰', 'ë³´ìŠµ', 'ê³ ë³´ìŠµ', 'í”¼ë¶€ìœ ì—°', 'í”¼ë¶€ê²°ì •ëˆ', 'í”¼ë¶€ì¥ë²½ê°•í™”', 'ë©€í‹°í¬ë¦¼', 'ë°¤íƒ€ì…', 'í”¼ë¶€ë³´í˜¸', 'í”¼ë¶€í™œë ¥', 'ë³´ìŠµíŒ¨ë“œ','AHA', 'PHA','ìœ ìˆ˜ë¶„ì¡°ì ˆ','ìœ ìˆ˜ë¶„ë°¸ëŸ°ìŠ¤'],
        'ìƒ‰ì†Œì¹¨ì°©': ['ê¸°ëŠ¥ì„±','ë¹„íƒ€ë¯¼í•¨ìœ ','AHA','ìŠ¤íŒŸì¼€ì–´']
    }
    user_concern_keywords = {
        'íŠ¸ëŸ¬ë¸”': ['ê¸°ëŠ¥ì„±','íŠ¸ëŸ¬ë¸”ì¼€ì–´', 'ì•½ì‚°ì„±', 'ì €ìê·¹', 'ë¯¼ê°ì„±', 'í”¼ì§€ì¡°ì ˆ', 'ë…¸íë¬¼ì œê±°', 'í”¼ë¶€ì§„ì •', 'ìŠ¤íŒŸì¼€ì–´', 'í”¼ë¶€ì¬ìƒ', 'ì˜¤ì¼í”„ë¦¬', 'ì•ˆí‹°í´ë£¨ì…˜','BHA', 'LHA'],
        'í”¼ë¶€í†¤': ['ë¯¸ë°±', 'ë¸Œë¼ì´íŠ¸ë‹', 'í†¤ì—…', 'í”¼ë¶€í†¤ë³´ì •', 'í”¼ë¶€íˆ¬ëª…', 'ê´‘ì±„', 'ìƒê¸°ë¶€ì—¬', 'í”¼ë¶€í™œë ¥', 'ë¹„íƒ€ë¯¼í•¨ìœ ','ë‹¤í¬ì„œí´ì™„í™”','ì•ˆí‹°ë‹¤í¬ë‹'],
        'ê°ì§ˆ/í”¼ë¶€ê²°': ['ê°ì§ˆê´€ë¦¬', 'ê°ì§ˆì¼€ì–´', 'í”¼ë¶€ê²°ì •ëˆ', 'í”¼ë¶€ìœ ì—°', 'AHA', 'BHA', 'PHA', 'LHA', 'í”¼ì§€ì¡°ì ˆ', 'ë³´ìŠµ', 'ê³ ë³´ìŠµ','ë…¸íë¬¼ì œê±°', 'í”¼ë¶€ì¥ë²½ê°•í™”'],
        'ë¯¼ê°ì„±': ['ë¯¼ê°ì„±', 'ì €ìê·¹', 'ì•½ì‚°ì„±', 'í”¼ë¶€ì§„ì •', 'í”¼ë¶€ë³´í˜¸', 'í´ë¦°ë·°í‹°', 'í”¼ë¶€ì¥ë²½ê°•í™”', 'ë¹„ê±´ë·°í‹°', 'í¬ë£¨ì–¼í‹°í”„ë¦¬','PHA', 'LHA','ì•ˆí‹°í´ë£¨ì…˜'],
        'ìì™¸ì„  ì°¨ë‹¨': ['ìì™¸ì„ ì°¨ë‹¨'],
        'ìœ ê¸°ë†': ['ìœ ê¸°ë†í™”ì¥í’ˆ', 'í´ë¦°ë·°í‹°', 'ì œë¡œì›¨ì´ìŠ¤íŠ¸', 'ì¹œí™˜ê²½', 'ë¹„ê±´ë·°í‹°', 'í¬ë£¨ì–¼í‹°í”„ë¦¬', 'í•œë°©í™”ì¥í’ˆ']
    }

    # ì‚¬ìš©ì ê³ ë¯¼ ê¸°ë°˜ 1ì°¨ í•„í„°ë§
    filtered_products = products.copy()
    if user_selected_concerns:
        concern_keywords_flat = set()
        for u in user_selected_concerns:
            concern_keywords_flat.update(user_concern_keywords.get(u, []))
        filtered_products = products[products['íƒœê·¸'].apply(lambda t: any(kw in str(t) for kw in concern_keywords_flat))]

    def score_product(row, user_concerns, user_selected_concerns):
        tags = str(row['íƒœê·¸'])
        tag_set = set([tag.strip().replace("#", "") for tag in tags.split(',')])
        
        score = 0
        for concern in concern_keywords:
            for keyword in concern_keywords[concern]:
                if keyword in tag_set:
                    if concern in user_concerns and any(keyword in user_concern_keywords.get(u, []) for u in user_selected_concerns):
                        score += 5
                    elif concern in user_concerns:
                        score += 3
                    elif any(keyword in user_concern_keywords.get(u, []) for u in user_selected_concerns):
                        score += 2
                    break
        return int(score)

    # ì ìˆ˜ ê³„ì‚° ë° ì¶”ì²œ ì¶”ì¶œ
    filtered_products['score'] = filtered_products.apply(lambda row: score_product(row, user_concerns, user_selected_concerns), axis=1)
    recommended = filtered_products[filtered_products['score'] > 0].sort_values(by='score', ascending=False).head(5)

    # ì ìˆ˜ 0ê°œë©´ fallback
    if len(recommended) == 0 and user_concerns:
        products['score'] = products.apply(lambda row: score_product(row, user_concerns, []), axis=1)
        recommended = products[products["score"] > 0].sort_values(by="score", ascending=False).head(5)

    def safe_row(row):
        return {
            "ë¸Œëœë“œ": str(row.get("ë¸Œëœë“œ", "")),
            "ì œí’ˆëª…": str(row.get("ì œí’ˆëª…", "")),
            "ìš©ëŸ‰/ê°€ê²©": str(row.get("ìš©ëŸ‰/ê°€ê²©", "")),
            "ë³„ì ": str(row.get("ë³„ì ", "")),
            "ì´ë¯¸ì§€": str(row.get("ì´ë¯¸ì§€", "")),
            "ì œí’ˆë§í¬": str(row.get("ì œí’ˆë§í¬", "")),
            "íƒœê·¸": [tag.strip().replace("#", "") for tag in str(row.get("íƒœê·¸", "")).split(",") if tag.strip()]
        }

    return [safe_row(row) for _, row in recommended.iterrows()]


def map_to_csv_key(gender: str, age_group: str) -> str:
    gender_map = {
        "ì—¬": "ì—¬ì„±",
        "ë‚¨": "ë‚¨ì„±",
        "ì—¬ì„±": "ì—¬ì„±",
        "ë‚¨ì„±": "ë‚¨ì„±"
    }
    age_map = {
        "10ëŒ€": "10~19",
        "20ëŒ€": "20~29",
        "30ëŒ€": "30~39",
        "40ëŒ€": "40~49",
        "50ëŒ€": "50~59",
        "60ëŒ€ ì´ìƒ": "60~69"
    }

    if gender not in gender_map or age_group not in age_map:
        raise ValueError(f"â— ì˜ëª»ëœ ì…ë ¥: gender={gender}, age_group={age_group}")

    return f"{gender_map[gender]}/{age_map[age_group]}"


@app.post("/analyze-recommend")
async def analyze_and_recommend(
    file: UploadFile = File(...),
    gender: str = Form(...),
    age_group: str = Form(...),
    concerns: Optional[List[str]] = Form(None)  # âœ… ë°°ì—´ë¡œ ë°›ê¸°
):
    image_bytes = await file.read()
    try:
        gender_age = map_to_csv_key(gender, age_group)
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        result = model_image(image, gender_age)

        recommended = recommend_products(
            regions=result.get("regions"),
            priority_concern=result.get("priority_concern"),
            user_selected_concerns=concerns  # âœ… ê·¸ëŒ€ë¡œ ì „ë‹¬
        )

        response_data = {
            "analysis": result,
            "recommend": recommended,
            "ê·¸ë˜í”„": result.get("z_score_avg")
        }

        return JSONResponse(content=response_data)

    except Exception as e:
        print("ğŸš¨ ì²˜ë¦¬ ì—ëŸ¬:", e)
        return JSONResponse(content={"error": str(e)}, status_code=500)
