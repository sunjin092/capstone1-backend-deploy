# âœ… main.py (CV ë¶„ì„ + ì¶”ì²œ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©)

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image, ImageOps
import pandas as pd
import json
import io
import numpy as np
import math
import os
import torch
import torch.nn as nn
from torchvision import transforms, models
import cv2
import mediapipe as mp
from typing import List, Optional
from sklearn.preprocessing import StandardScaler

# FastAPI ì•± ìƒì„±
app = FastAPI()

# CORS ì„¤ì •
origins = [
    "http://localhost:3000",
    "https://jiwow-wow.github.io",
    "https://front-seven-chi.vercel.app"
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê³µí†µ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

regression_ckpt = os.path.join("checkpoint", "regression")
regression_num_output = [1, 2, 0, 0, 0, 3, 3, 0, 2]
area_label = {0: "ì „ì²´", 1: "ì´ë§ˆ", 2: "ë¯¸ê°„", 3: "ì™¼ìª½ ëˆˆê°€", 4: "ì˜¤ë¥¸ìª½ ëˆˆê°€", 5: "ì™¼ìª½ ë³¼", 6: "ì˜¤ë¥¸ìª½ ë³¼", 7: "ì…ìˆ ", 8: "í„±"}
reg_desc = {0: ["ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜"], 1: ["ìˆ˜ë¶„", "íƒ„ë ¥"], 5: ["ìˆ˜ë¶„", "íƒ„ë ¥", "ëª¨ê³µ ê°œìˆ˜"], 6: ["ìˆ˜ë¶„", "íƒ„ë ¥", "ëª¨ê³µ ê°œìˆ˜"], 8: ["ìˆ˜ë¶„", "íƒ„ë ¥"]}

REGION_LANDMARKS = {
    0: list(range(468)),
    1: [10, 67, 69, 71, 109, 151, 337, 338, 297],
    2: [168, 6, 197, 195, 5, 4],
    3: [130, 133, 160, 159, 158],
    4: [359, 362, 386, 385, 384],
    5: [205, 50, 187, 201, 213],
    6: [425, 280, 411, 427, 434],
    7: [13, 14, 17, 84, 181],
    8: [152, 377, 400, 378, 379]
}

def crop_regions_by_ratio(pil_img):
    img = np.array(pil_img)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    h, w = img.shape[:2]
    regions = [None] * 9
    with mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:
        results = face_mesh.process(img_rgb)
        if not results.multi_face_landmarks:
            raise ValueError("â— ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        landmarks = results.multi_face_landmarks[0].landmark
        points = np.array([(lm.x * w, lm.y * h) for lm in landmarks])
        face_x1, face_y1 = np.min(points, axis=0)
        face_x2, face_y2 = np.max(points, axis=0)
        face_w, face_h = face_x2 - face_x1, face_y2 - face_y1
        for idx, lm_indices in REGION_LANDMARKS.items():
            pts = np.array([(landmarks[i].x * w, landmarks[i].y * h) for i in lm_indices])
            cx, cy = np.mean(pts, axis=0)
            if idx == 8: cx -= face_w * 0.15
            if idx == 1:
                box_w, box_h = int(face_w * 0.70), int(face_h * 0.3)
                cy -= box_h * 0.2
            elif idx == 2:
                box_w, box_h = int(face_w * 0.35), int(face_h * 0.15)
                cy -= box_h * 2.5
            else:
                box_w, box_h = int(face_w * 0.28), int(face_h * 0.25)
            x1, y1 = max(int(cx - box_w / 2), 0), max(int(cy - box_h / 2), 0)
            x2, y2 = min(int(cx + box_w / 2), w), min(int(cy + box_h / 2), h)
            crop = img[y1:y2, x1:x2]
            regions[idx] = Image.fromarray(crop)
    return regions

def load_average_data(path):
    df = pd.read_csv(path, encoding='cp949')
    avg_dict = {}
    for _, row in df.iterrows():
        key = row["ì„±ë³„"]
        avg_dict[key] = {
            "mean": {
                "ìˆ˜ë¶„_ì´ë§ˆ": row["ìˆ˜ë¶„_ì´ë§ˆ"],
                "ìˆ˜ë¶„_ì™¼ìª½ ë³¼": row["ìˆ˜ë¶„_ì™¼ìª½ ë³¼"],
                "ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼": row["ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼"],
                "ìˆ˜ë¶„_í„±": row["ìˆ˜ë¶„_í„±"],
                "íƒ„ë ¥_ì´ë§ˆ": row["íƒ„ë ¥_ì´ë§ˆ"],
                "íƒ„ë ¥_ì™¼ìª½ ë³¼": row["íƒ„ë ¥_ì™¼ìª½ ë³¼"],
                "íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼": row["íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼"],
                "íƒ„ë ¥_í„±": row["íƒ„ë ¥_í„±"],
                "ëª¨ê³µ ê°œìˆ˜_ì™¼ìª½ ë³¼": row["ëª¨ê³µ ê°œìˆ˜_ì™¼ìª½ ë³¼"],
                "ëª¨ê³µ ê°œìˆ˜_ì˜¤ë¥¸ìª½ ë³¼": row["ëª¨ê³µ ê°œìˆ˜_ì˜¤ë¥¸ìª½ ë³¼"],
                "ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜_ì „ì²´": row["ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜_ì „ì²´"]
            },
            "std": {
                "ìˆ˜ë¶„_ì´ë§ˆ": row["ìˆ˜ë¶„_ì´ë§ˆ_í‘œì¤€í¸ì°¨"],
                "ìˆ˜ë¶„_ì™¼ìª½ ë³¼": row["ìˆ˜ë¶„_ì™¼ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼": row["ìˆ˜ë¶„_ì˜¤ë¥¸ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ìˆ˜ë¶„_í„±": row["ìˆ˜ë¶„_í„±_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_ì´ë§ˆ": row["íƒ„ë ¥_ì´ë§ˆ_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_ì™¼ìª½ ë³¼": row["íƒ„ë ¥_ì™¼ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼": row["íƒ„ë ¥_ì˜¤ë¥¸ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "íƒ„ë ¥_í„±": row["íƒ„ë ¥_í„±_í‘œì¤€í¸ì°¨"],
                "ëª¨ê³µ ê°œìˆ˜_ì™¼ìª½ ë³¼": row["ëª¨ê³µ ê°œìˆ˜_ì™¼ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ëª¨ê³µ ê°œìˆ˜_ì˜¤ë¥¸ìª½ ë³¼": row["ëª¨ê³µ ê°œìˆ˜_ì˜¤ë¥¸ìª½ ë³¼_í‘œì¤€í¸ì°¨"],
                "ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜_ì „ì²´": row["ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜_ì „ì²´_í‘œì¤€í¸ì°¨"]
            }
        }
    return avg_dict

def compute_z_score(value, mean, std):
    if std == 0:
        return 0
    return round((value - mean) / std, 2)

def safe_float(val, default=0.0):
    try:
        if val is None or math.isnan(val) or math.isinf(val):
            return default
        return float(val)
    except:
        return default

def get_restore_stats():
    return {
        1: {"ìˆ˜ë¶„": (60.6, 10.1), "íƒ„ë ¥": (48.7, 11.9)},
        5: {"ìˆ˜ë¶„": (60.6, 10.1), "íƒ„ë ¥": (48.7, 11.9), "ëª¨ê³µ ê°œìˆ˜": "log"},
        6: {"ìˆ˜ë¶„": (60.2, 9.6),  "íƒ„ë ¥": (49.3, 12.1), "ëª¨ê³µ ê°œìˆ˜": "log"},
        8: {"ìˆ˜ë¶„": (61.3, 10.0), "íƒ„ë ¥": (47.5, 12.0)},
        0: {"ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜": 300}
    }

# íšŒê·€ ëª¨ë¸ ë¡œë”©
restore_stats = get_restore_stats()
reg_models = []
for idx, out_dim in enumerate(regression_num_output):
    if out_dim == 0:
        reg_models.append(None)
        continue
    model = models.resnet50(weights=None)
    model.fc = nn.Linear(model.fc.in_features, out_dim)
    ckpt_path = os.path.join(regression_ckpt, str(idx), "state_dict.bin")
    if os.path.exists(ckpt_path):
        state = torch.load(ckpt_path, map_location=device)
        if "model_state" in state:
            state = state["model_state"]
        model.load_state_dict(state, strict=False)
        model.eval()
        reg_models.append(model.to(device))
    else:
        reg_models.append(None)

def model_image(image: Image.Image, gender_age: str, average_data_path="average_data.csv") -> dict:
    image = ImageOps.exif_transpose(image.convert("RGB"))
    regions = crop_regions_by_ratio(image)
    result = {"regions": {}, "z_scores": {}, "priority_concern": None}

    avg_data = load_average_data(average_data_path)
    if gender_age not in avg_data:
        raise ValueError(f"â— í‰ê·  ë°ì´í„°ì— '{gender_age}' í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    mean_dict = avg_data[gender_age]["mean"]
    std_dict = avg_data[gender_age]["std"]

    z_score_list = []

    for idx in range(9):
        if reg_models[idx] is None or regions[idx] is None or idx in [3, 4]:
            continue
        crop_tensor = transform(regions[idx]).unsqueeze(0).to(device)
        with torch.no_grad():
            output = reg_models[idx](crop_tensor).squeeze().cpu().numpy()
        if output.ndim == 0:
            output = [output]
        sub_result, sub_zscore = {}, {}
        for i, val in enumerate(output):
            label = reg_desc[idx][i]
            if label == "ëª¨ê³µ ê°œìˆ˜" and restore_stats[idx].get(label) == "log":
                val = np.clip(np.exp(val) - 1, 0, 2500)
            elif isinstance(restore_stats[idx].get(label), tuple):
                mean, std = restore_stats[idx][label]
                val = val * std + mean
            elif label == "ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜":
                val *= 300
            val = float(val)
            sub_result[label] = round(val, 2)
            z_key = f"{label}_{area_label[idx]}" if label != "ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜" else "ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜_ì „ì²´"
            if z_key in mean_dict:
                z = compute_z_score(val, mean_dict[z_key], std_dict[z_key])
                sub_zscore[label] = z
                z_score_list.append((label, area_label[idx], z))
        result["regions"][area_label[idx]] = sub_result
        if sub_zscore:
            result["z_scores"][area_label[idx]] = sub_zscore

    concerns = []
    for label, area, z in z_score_list:
        if label in ["ìˆ˜ë¶„", "íƒ„ë ¥"] and z < -0.2:
            concerns.append((label, area, z))
        elif label in ["ëª¨ê³µ ê°œìˆ˜", "ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜"] and z > 0.2:
            concerns.append((label, area, z))
    if concerns:
        result["priority_concern"] = sorted(concerns, key=lambda x: abs(x[2]), reverse=True)[0]

    return result

# í™”ì¥í’ˆ CSV ë¡œë“œ
products = pd.read_csv("Total_DB.csv", encoding='cp949')

# ì¶”ì²œ í•¨ìˆ˜ ì •ì˜
def recommend_products(skin_type: str, regions: dict, priority_concern: Optional[tuple], user_selected_concerns: Optional[List[str]] = None):
    moisture_values = {
        'ì´ë§ˆ': regions.get('ì´ë§ˆ', {}).get('ìˆ˜ë¶„', 0),
        'ì™¼ìª½ ë³¼': regions.get('ì™¼ìª½ ë³¼', {}).get('ìˆ˜ë¶„', 0),
        'ì˜¤ë¥¸ìª½ ë³¼': regions.get('ì˜¤ë¥¸ìª½ ë³¼', {}).get('ìˆ˜ë¶„', 0),
        'í„±': regions.get('í„±', {}).get('ìˆ˜ë¶„', 0)
    }
    elasticity_avg = np.mean([
        regions.get('ì´ë§ˆ', {}).get('íƒ„ë ¥', 0),
        regions.get('ì™¼ìª½ ë³¼', {}).get('íƒ„ë ¥', 0),
        regions.get('ì˜¤ë¥¸ìª½ ë³¼', {}).get('íƒ„ë ¥', 0),
        regions.get('í„±', {}).get('íƒ„ë ¥', 0)
    ])
    pore_avg = np.mean([
        regions.get('ì™¼ìª½ ë³¼', {}).get('ëª¨ê³µ ê°œìˆ˜', 0),
        regions.get('ì˜¤ë¥¸ìª½ ë³¼', {}).get('ëª¨ê³µ ê°œìˆ˜', 0)
    ])
    pigment_avg = regions.get('ì „ì²´', {}).get('ìƒ‰ì†Œì¹¨ì°© ê°œìˆ˜', 0)

    low_moisture_vals = [v for v in moisture_values.values() if v < 62]
    if len(low_moisture_vals) > 0:
        low_moisture_avg = np.mean(low_moisture_vals)
        moisture_score = (62 - low_moisture_avg) / 62
    else:
        moisture_score = 0

    raw_scores = [
        (pore_avg - 400) / 400 if pore_avg >= 400 else 0,
        (50 - elasticity_avg) / 50 if elasticity_avg <= 50 else 0,
        moisture_score,
        (pigment_avg - 130) / 130 if pigment_avg >= 130 else 0
    ]
    concern_keys = ['ëª¨ê³µ', 'íƒ„ë ¥', 'ìˆ˜ë¶„', 'ìƒ‰ì†Œì¹¨ì°©']

    scaler = StandardScaler()
    scaled_scores = scaler.fit_transform(np.array(raw_scores).reshape(-1, 1)).flatten()
    concern_scores = dict(zip(concern_keys, scaled_scores))

    if priority_concern:
        priority_label = priority_concern[0]
        user_concerns = [priority_label]
    else:
        user_concerns = []

    if user_selected_concerns is None:
        user_selected_concerns = ['íŠ¸ëŸ¬ë¸”']

    concern_keywords = {
        'ëª¨ê³µ': ['ëª¨ê³µê´€ë¦¬', 'ëª¨ê³µì¼€ì–´', 'í”¼ì§€ì¡°ì ˆ', 'ë…¸íë¬¼ì œê±°', 'ì•ˆí‹°í´ë£¨ì…˜','BHA', 'LHA'],
        'íƒ„ë ¥': ['í”¼ë¶€íƒ„ë ¥', 'ì£¼ë¦„ê°œì„ ', 'í”¼ë¶€ì¥ë²½ê°•í™”', 'í”¼ë¶€ì¬ìƒ', 'ì˜ì–‘ê³µê¸‰', 'ì•°í”Œ', 'í”¼ë¶€í™œë ¥', 'ìƒê¸°ë¶€ì—¬'],
        'ìˆ˜ë¶„': ['ìˆ˜ë¶„ê³µê¸‰', 'ë³´ìŠµ', 'ê³ ë³´ìŠµ', 'í”¼ë¶€ìœ ì—°', 'í”¼ë¶€ê²°ì •ëˆ', 'í”¼ë¶€ì¥ë²½ê°•í™”', 'ë©€í‹°í¬ë¦¼', 'ë°¤íƒ€ì…', 'í”¼ë¶€ë³´í˜¸', 'í”¼ë¶€í™œë ¥', 'ë³´ìŠµíŒ¨ë“œ','AHA', 'PHA','ìœ ìˆ˜ë¶„ì¡°ì ˆ','ìœ ìˆ˜ë¶„ë°¸ëŸ°ìŠ¤'],
        'ìƒ‰ì†Œì¹¨ì°©': ['ë¹„íƒ€ë¯¼í•¨ìœ ','AHA','ìŠ¤íŒŸì¼€ì–´']
    }
    user_concern_keywords = {
        'íŠ¸ëŸ¬ë¸”': ['íŠ¸ëŸ¬ë¸”ì¼€ì–´', 'ì•½ì‚°ì„±', 'ì €ìê·¹', 'ë¯¼ê°ì„±', 'í”¼ì§€ì¡°ì ˆ', 'ë…¸íë¬¼ì œê±°', 'í”¼ë¶€ì§„ì •', 'ìŠ¤íŒŸì¼€ì–´', 'í”¼ë¶€ì¬ìƒ', 'ì˜¤ì¼í”„ë¦¬', 'ì•ˆí‹°í´ë£¨ì…˜','BHA', 'LHA'],
        'í”¼ë¶€í†¤': ['ë¯¸ë°±', 'ë¸Œë¼ì´íŠ¸ë‹', 'í†¤ì—…', 'í”¼ë¶€í†¤ë³´ì •', 'íˆ¬ëª…í”¼ë¶€', 'ê´‘ì±„', 'ìƒê¸°ë¶€ì—¬', 'í”¼ë¶€í™œë ¥', 'ë¹„íƒ€ë¯¼í•¨ìœ ','ë‹¤í¬ì„œí´ì™„í™”','ì•ˆí‹°ë‹¤í¬ë‹'],
        'ê°ì§ˆ/í”¼ë¶€ê²°': ['ê°ì§ˆê´€ë¦¬', 'ê°ì§ˆì¼€ì–´', 'í”¼ë¶€ê²°ì •ëˆ', 'í”¼ë¶€ìœ ì—°', 'AHA', 'BHA', 'PHA', 'LHA', 'í”¼ì§€ì¡°ì ˆ', 'ë³´ìŠµ', 'ê³ ë³´ìŠµ','ë…¸íë¬¼ì œê±°', 'í”¼ë¶€ì¥ë²½ê°•í™”'],
        'ë¯¼ê°ì„±': ['ë¯¼ê°ì„±', 'ì €ìê·¹', 'ì•½ì‚°ì„±', 'í”¼ë¶€ì§„ì •', 'í”¼ë¶€ë³´í˜¸', 'í´ë¦°ë·°í‹°', 'í”¼ë¶€ì¥ë²½ê°•í™”', 'ë¹„ê±´ë·°í‹°', 'í¬ë£¨ì–¼í‹°í”„ë¦¬','PHA', 'LHA','ì•ˆí‹°í´ë£¨ì…˜'],
        'ìì™¸ì„  ì°¨ë‹¨': ['ìì™¸ì„ ì°¨ë‹¨'],
        'ìœ ê¸°ë†': ['ìœ ê¸°ë†í™”ì¥í’ˆ', 'í´ë¦°ë·°í‹°', 'ì œë¡œì›¨ì´ìŠ¤íŠ¸', 'ì¹œí™˜ê²½', 'ë¹„ê±´ë·°í‹°', 'í¬ë£¨ì–¼í‹°í”„ë¦¬', 'í•œë°©í™”ì¥í’ˆ']
    }

    def score_product(row):
        tags = str(row['íƒœê·¸'])
        tag_set = set([tag.strip() for tag in tags.split(',')])
        score = 0
        for concern in concern_keywords:
            for keyword in concern_keywords[concern]:
                for tag in tag_set:
                    if keyword == tag:
                        if concern in user_concerns and any(keyword in user_concern_keywords.get(u, []) for u in user_selected_concerns):
                            score += 5
                        elif concern in user_concerns:
                            score += 3
                        elif any(keyword in user_concern_keywords.get(u, []) for u in user_selected_concerns):
                            score += 2
                        break
        return score

    products['score'] = products.apply(score_product, axis=1)
    recommended = products[products['score'] > 0].sort_values(by='score', ascending=False).head(5)

    def safe_row(row):
        return {
            "ë¸Œëœë“œ": str(row.get("ë¸Œëœë“œ", "")),
            "ì œí’ˆëª…": str(row.get("ì œí’ˆëª…", "")),
            "ìš©ëŸ‰/ê°€ê²©": str(row.get("ìš©ëŸ‰/ê°€ê²©", "")),
            "ë³„ì ": safe_float(row.get("ë³„ì ", 0.0)),
            "ì´ë¯¸ì§€": str(row.get("ì´ë¯¸ì§€", ""))
        }

    return [safe_row(row) for _, row in recommended.iterrows()]

# âœ… ìµœì¢… API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze-recommend")
async def analyze_and_recommend(
    file: UploadFile = File(...),
    gender: str = Form(...),
    age: int = Form(...),
    concerns: Optional[str] = Form(None)  # JSON ë¬¸ìì—´
):
    image_bytes = await file.read()
    try:
        gender_age = f"{gender}_{(age // 10) * 10}ëŒ€"
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        result = model_image(image, gender_age)

        user_selected_concerns = json.loads(concerns) if concerns else None
        recommended = recommend_products(
            skin_type=None,
            regions=result.get("regions"),
            priority_concern=result.get("priority_concern"),
            user_selected_concerns=user_selected_concerns
        )

        response_data = {
            "analysis": result,
            "recommend": recommended
        }

        safe_json = json.dumps(response_data, ensure_ascii=False, allow_nan=False)
        return JSONResponse(content=json.loads(safe_json))

    except Exception as e:
        print("ğŸš¨ ì²˜ë¦¬ ì—ëŸ¬:", e)
        return JSONResponse(content={"error": str(e)}, status_code=500)